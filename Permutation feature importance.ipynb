{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation feature importance is a model inspection technique that can be used for any fitted estimator when the data is tabular. This is especially useful for non-linear or opaque estimators. The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled. This procedure breaks the relationship between the feature and the target, thus the drop in the model score is indicative of how much the model depends on the feature. This technique benefits from being model agnostic and can be calculated many times with different permutations of the feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function that will read the data and the number of important features and return the false positives with original fratures, feature importance score_orig-score_perm, and fp with the given number of important features\n",
    "1. Read the credit data set (train and test)\n",
    "2. Predict the test set with Decision Tree Classifier and return the original model score and the number of false positives\n",
    "3. Iterate through all the features np.random.permutation and calculate the feature importance as score_orig - score_temp\n",
    "4. Create dictinary with FP without permutation, tuple of important features in an ascending order, and FP using n most \n",
    "important features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:,:-1]\n",
    "X_test = df_test.iloc[:,:-1]\n",
    "y_train = df_train.iloc[:,-1:]\n",
    "y_test = df_test.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classification(X_train,X_test,y_train,y_test):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn import metrics\n",
    "    # Create Decision Tree classifer object\n",
    "    random_state = np.random.seed(0)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #Measure accuracy\n",
    "    accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "    #Measure FP from confusion matrix\n",
    "    tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "    class_report = sklearn.metrics.classification_report(y_test, y_pred)\n",
    "    return accuracy, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Importance(X_train,X_test,y_train,y_test, n):\n",
    "    Output = {}\n",
    "    # Calculating the original score and original FP\n",
    "    score_orig, fp_orig=Classification(X_train,X_test,y_train,y_test)   \n",
    "    \n",
    "    # Data frame with feature importance\n",
    "    df_import=pd.DataFrame(columns=['Feature Name', 'Importance'])\n",
    "    X_test_copy = X_test.copy()\n",
    "    X_train_copy = X_train.copy()\n",
    "    for ind, column in enumerate(X_train.columns):\n",
    "        X_train_temp = X_train_copy.copy()\n",
    "        np.random.seed(0)\n",
    "        X_train_temp.iloc[:,ind]=np.random.permutation(X_train_copy.iloc[:,ind])\n",
    "        score_x, fp_x = Classification(X_train_temp,X_test,y_train,y_test)\n",
    "        permuation_feature_importance = score_orig - score_x\n",
    "        df_import.loc[ind]=[column,permuation_feature_importance]\n",
    "    df_import=df_import.sort_values(['Importance'],ascending=False)\n",
    "    print(df_import.head(n))\n",
    "    tup=list(df_import.iloc[:,:].to_records(index=False))\n",
    "    my_list=df_import['Importance'].nlargest(n=n).index\n",
    "    \n",
    "    X_train_import=X_train.iloc[:,my_list]\n",
    "    X_test_import=X_test.iloc[:,my_list] \n",
    "    score_import, fp_import=Classification(X_train_import,X_test_import,y_train,y_test)\n",
    "    # Create the Output Dictionary\n",
    "    Output['false positive without permutation'] = fp_orig\n",
    "    Output['accuracy without permutation'] = score_orig\n",
    "    Output['Feature Importance'] = tup\n",
    "    Output['false positive using n important features'] = fp_import\n",
    "    Output['accuracy using n important features'] = score_import\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature Name  Importance\n",
      "40  other_installment_plans_A143        0.07\n",
      "9    checking_account_status_A14        0.07\n",
      "11            credit_history_A32        0.07\n",
      "46                telephone_A192        0.06\n",
      "3              present_residence        0.06\n"
     ]
    }
   ],
   "source": [
    "Dict = Feature_Importance(X_train,X_test,y_train,y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'false positive without permutation': 14, 'accuracy without permutation': 0.69, 'Feature Importance': [('other_installment_plans_A143', 0.07), ('checking_account_status_A14', 0.07), ('credit_history_A32', 0.07), ('telephone_A192', 0.06), ('present_residence', 0.06), ('job_A172', 0.06), ('credit_history_A34', 0.05), ('credit_amount', 0.05), ('other_debtors_A102', 0.05), ('savings_A63', 0.04), ('property_A122', 0.04), ('purpose_A43', 0.04), ('present_employment_A75', 0.04), ('present_employment_A74', 0.04), ('credit_history_A33', 0.04), ('credit_history_A31', 0.04), ('purpose_A41', 0.03), ('purpose_A44', 0.03), ('property_A123', 0.03), ('purpose_A48', 0.03), ('personal_A94', 0.03), ('personal_A93', 0.03), ('present_employment_A72', 0.03), ('purpose_A42', 0.02), ('checking_account_status_A12', 0.02), ('existing_credits', 0.02), ('personal_A92', 0.02), ('job_A173', 0.01), ('job_A174', 0.01), ('housing_A152', 0.01), ('duration', 0.01), ('present_employment_A73', 0.01), ('checking_account_status_A13', 0.01), ('savings_A64', 0.01), ('installment_rate', 0.01), ('purpose_A45', 0.01), ('purpose_A410', 0.01), ('savings_A62', 0.), ('age', 0.), ('property_A124', 0.), ('savings_A65', 0.), ('dependents', -0.01), ('foreign_worker_A202', -0.01), ('purpose_A46', -0.01), ('other_debtors_A103', -0.01), ('purpose_A49', -0.02), ('other_installment_plans_A142', -0.02), ('housing_A153', -0.04)], 'false positive using n important features': 1, 'accuracy using n important features': 0.7}\n"
     ]
    }
   ],
   "source": [
    "print(Dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
